{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project #1 - Shraddha Upadhyay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools \n",
    "import prince\n",
    "import gower\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "data = pd.read_csv('train.csv')\n",
    "data = data.drop('Id', axis = 1)\n",
    "\n",
    "# Remove columns that have too many missing values\n",
    "data = data.drop(data.columns[data.isnull().sum() > 30], axis = 1)\n",
    "\n",
    "# Remove missing values\n",
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code starts here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "0          60       RL     8450   Pave      Reg         Lvl    AllPub   \n",
       "1          20       RL     9600   Pave      Reg         Lvl    AllPub   \n",
       "2          60       RL    11250   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "  LotConfig LandSlope Neighborhood  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    Inside       Gtl      CollgCr  ...             0         0           0   \n",
       "1       FR2       Gtl      Veenker  ...             0         0           0   \n",
       "2    Inside       Gtl      CollgCr  ...             0         0           0   \n",
       "\n",
       "  PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition SalePrice  \n",
       "0        0        0       2    2008        WD        Normal    208500  \n",
       "1        0        0       5    2007        WD        Normal    181500  \n",
       "2        0        0       9    2008        WD        Normal    223500  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating X and y\n",
    "X = data.drop('SalePrice', axis = 1)\n",
    "y = data.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, validate, test and split\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, random_state=201)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.2, random_state=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train valid:  (1160, 63)\n",
      "X test       :  (291, 63)\n",
      "y train valid:  (1160,)\n",
      "y test       :  (291,)\n",
      "X train      :  (928, 63)\n",
      "X valid      :  (232, 63)\n",
      "y train      :  (928,)\n",
      "y valid      :  (232,)\n"
     ]
    }
   ],
   "source": [
    "print('X train valid: ',X_train_valid.shape)\n",
    "print('X test       : ',X_test.shape)\n",
    "print('y train valid: ',y_train_valid.shape)\n",
    "print('y test       : ',y_test.shape)\n",
    "print('X train      : ',X_train.shape)\n",
    "print('X valid      : ',X_valid.shape)\n",
    "print('y train      : ',y_train.shape)\n",
    "print('y valid      : ',y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will separate our features into numerical and categorical types\n",
    "XTrainValidNum = X_train_valid.select_dtypes(include=[np.number]) #for PCA\n",
    "XTrainValidCat = X_train_valid.select_dtypes(exclude=[np.number]) #for MCA\n",
    "\n",
    "XTrainNum = X_train.select_dtypes(include=[np.number]) #for PCA\n",
    "XTrainCat = X_train.select_dtypes(exclude=[np.number]) #for MCA\n",
    "\n",
    "XValidNum = X_valid.select_dtypes(include=[np.number]) #for PCA\n",
    "XValidCat = X_valid.select_dtypes(exclude=[np.number]) #for MCA\n",
    "\n",
    "XTestNum = X_test.select_dtypes(include=[np.number]) #for PCA\n",
    "XTestCat = X_test.select_dtypes(exclude=[np.number]) #for MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train validation numerical        :  (1160, 34)\n",
      "X train validation categorical      :  (1160, 29)\n",
      "X train numerical                   :  (928, 34)\n",
      "X train categorical                 :  (928, 29)\n",
      "X test numerical                    :  (291, 34)\n",
      "X test categorical                  :  (291, 29)\n",
      "X valid numerical                   :  (232, 34)\n",
      "X valid categorical                 :  (232, 29)\n"
     ]
    }
   ],
   "source": [
    "# Printing the size \n",
    "print('X train validation numerical        : ',XTrainValidNum.shape)\n",
    "print('X train validation categorical      : ',XTrainValidCat.shape)\n",
    "print('X train numerical                   : ',XTrainNum.shape)\n",
    "print('X train categorical                 : ',XTrainCat.shape)\n",
    "print('X test numerical                    : ',XTestNum.shape)\n",
    "print('X test categorical                  : ',XTestCat.shape)\n",
    "print('X valid numerical                   : ',XValidNum.shape)\n",
    "print('X valid categorical                 : ',XValidCat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the training feature and testing feature has same number of levels\n",
    "keep = XTrainValidCat.nunique() == XTestCat.nunique() \n",
    "XTrainValidCat = XTrainValidCat[XTrainValidCat.columns[keep]]\n",
    "XTestCat = XTestCat[XTestCat.columns[keep]]\n",
    "XTrainCat = XTrainCat[XTrainCat.columns[keep]]\n",
    "XValidCat = XValidCat[XValidCat.columns[keep]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepN = XTrainCat.nunique() == XValidCat.nunique()\n",
    "XTrainValidCat = XTrainValidCat[XTrainValidCat.columns[keepN]]\n",
    "XTrainCat = XTrainCat[XTrainCat.columns[keepN]]\n",
    "XValidCat = XValidCat[XValidCat.columns[keepN]]\n",
    "XTestCat = XTestCat[XTestCat.columns[keepN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For categorical features that have same levels, making sure the classes are the same\n",
    "keep = []\n",
    "for i in range(XTrainValidCat.shape[1]):\n",
    "    keep.append(all(np.sort(XTrainValidCat.iloc[:,i].unique()) == np.sort(XTestCat.iloc[:,i].unique())))\n",
    "XTrainValidCat = XTrainValidCat[XTrainValidCat.columns[keep]]\n",
    "XTestCat = XTestCat[XTestCat.columns[keep]]\n",
    "XTrainCat = XTrainCat[XTrainCat.columns[keep]]\n",
    "XValidCat = XValidCat[XValidCat.columns[keep]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_1 = []\n",
    "for j in range(XTrainCat.shape[1]):\n",
    "    keep_1.append(all(np.sort(XTrainCat.iloc[:,j].unique()) == np.sort(XValidCat.iloc[:,j].unique())))\n",
    "XTrainCat = XTrainCat[XTrainCat.columns[keep_1]]\n",
    "XValidCat = XValidCat[XValidCat.columns[keep_1]]\n",
    "XTrainValidCat = XTrainValidCat[XTrainValidCat.columns[keep_1]]\n",
    "XTestCat = XTestCat[XTestCat.columns[keep_1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us scale the data for training and validation sets \n",
    "scaleddata = StandardScaler()\n",
    "scaleddata.fit(XTrainNum)\n",
    "\n",
    "XTrainNumScale = pd.DataFrame(scaleddata.transform(XTrainNum))\n",
    "XValidNumScale = pd.DataFrame(scaleddata.transform(XValidNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create parameter lists for PCA and MCA\n",
    "PComponent = range(4, 8) #PCA\n",
    "MComponent = range(4, 8) #MCA\n",
    "MIter = range(4, 8)  #MCA\n",
    "\n",
    "ParameterList = list(itertools.product(PComponent, MComponent, MIter)) #List of paramters\n",
    "valid_score = [] #Validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us perform PCA and MCA\n",
    "for param in ParameterList:\n",
    "  pca = PCA(n_components=param[0], random_state=987)\n",
    "  mca = prince.MCA(n_components=param[1], n_iter=param[2], random_state=987)\n",
    " \n",
    "  # below we fit, transform and combine the numerical and categorical training data\n",
    "  XTrainNumT = pca.fit_transform(XTrainNumScale)    # fitting and transforming the training set\n",
    "  XTrainCatT = mca.fit_transform(XTrainCat)\n",
    "  XTrainComb = np.concatenate([XTrainNumT, XTrainCatT], axis=1) # Combining the training set\n",
    "\n",
    "  # fitting Knn model\n",
    "  knn = KNeighborsRegressor()\n",
    "  knn.fit(XTrainComb, y_train)\n",
    "\n",
    "  # below we fit, transform and combine the numerical and categorical validation data\n",
    "  XValidNumT = pca.transform(XValidNumScale)  # here we are transforming the validation set. we are not fitting it here\n",
    "  XValidCatT = mca.transform(XValidCat)\n",
    "  XValidCombined = np.concatenate([XValidNumT, XValidCatT], axis=1) # Combining the validation set\n",
    "\n",
    "  # lets us append the validation score for the hyperparameters\n",
    "  valid_score.append(mean_squared_error(knn.predict(XValidCombined), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components :  5\n",
      "MCA components :  4\n",
      "MCA iterations :  6\n"
     ]
    }
   ],
   "source": [
    "# let us try to find the best hyperparameters\n",
    "best_params = ParameterList[np.argmin(valid_score)]\n",
    "print(\"PCA components : \", best_params[0])\n",
    "print(\"MCA components : \", best_params[1])\n",
    "print(\"MCA iterations : \", best_params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us scale our training,testing and validation data again for prediction\n",
    "scaler_1 = StandardScaler()\n",
    "scaler_1.fit(XTrainValidNum)\n",
    "\n",
    "XTrainValidNumScale = pd.DataFrame(scaleddata.transform(XTrainValidNum))\n",
    "XTestNumScale = pd.DataFrame(scaleddata.transform(XTestNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train validation numerical        :  (1160, 34)\n",
      "X train validation categorical      :  (1160, 9)\n",
      "X train numerical                   :  (928, 34)\n",
      "X train categorical                 :  (928, 9)\n",
      "X test numerical                    :  (291, 34)\n",
      "X test categorical                  :  (291, 9)\n",
      "X valid numerical                   :  (232, 34)\n",
      "X valid categorical                 :  (232, 9)\n"
     ]
    }
   ],
   "source": [
    "# let's print sizes of the sets\n",
    "print('X train validation numerical        : ',XTrainValidNum.shape)\n",
    "print('X train validation categorical      : ',XTrainValidCat.shape)\n",
    "print('X train numerical                   : ',XTrainNum.shape)\n",
    "print('X train categorical                 : ',XTrainCat.shape)\n",
    "print('X test numerical                    : ',XTestNum.shape)\n",
    "print('X test categorical                  : ',XTestCat.shape)\n",
    "print('X valid numerical                   : ',XValidNum.shape)\n",
    "print('X valid categorical                 : ',XValidCat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us perform PCA and MCA \n",
    "pca1 = PCA(n_components=best_params[0], random_state=657)\n",
    "mca1 = prince.MCA(n_components=best_params[1], n_iter=best_params[2], random_state=657)\n",
    " \n",
    "# below we fit, transform and combine the numerical and categorical training data\n",
    "XTrainValidNumT = pca1.fit_transform(XTrainValidNum)  #Now We fit_transform & train+valid set\n",
    "XTrainValidCatT = mca1.fit_transform(XTrainValidCat)\n",
    "XTrainValidCombined = np.concatenate([XTrainValidNumT, XTrainValidCatT], axis=1)\n",
    "\n",
    "# let's use knn regressor\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(XTrainValidCombined, y_train_valid)\n",
    "\n",
    "# below we transform and combine the numerical and categorical validation data\n",
    "XTestNumT = pca1.transform(XTestNumScale) \n",
    "XTestCatT = mca1.transform(XTestCat)\n",
    "XTestCombined = np.concatenate([XTestNumT, XTestCatT], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on the test set is:  13159326099.05842\n"
     ]
    }
   ],
   "source": [
    "# printing error on the test set\n",
    "print(\"Error on the test set is: \",metrics.mean_squared_error(knn.predict(XTestCombined), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets us apply Ridge Regression to predict the score on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the regression, we need to create dummy variables\n",
    "numer = data.select_dtypes(include=[np.number]) #for PCA\n",
    "categ = data.select_dtypes(exclude=[np.number]) #for MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning_FV</th>\n",
       "      <th>MSZoning_RH</th>\n",
       "      <th>MSZoning_RL</th>\n",
       "      <th>MSZoning_RM</th>\n",
       "      <th>Street_Pave</th>\n",
       "      <th>LotShape_IR2</th>\n",
       "      <th>LotShape_IR3</th>\n",
       "      <th>LotShape_Reg</th>\n",
       "      <th>LandContour_HLS</th>\n",
       "      <th>LandContour_Low</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSZoning_FV  MSZoning_RH  MSZoning_RL  MSZoning_RM  Street_Pave  \\\n",
       "0            0            0            1            0            1   \n",
       "1            0            0            1            0            1   \n",
       "2            0            0            1            0            1   \n",
       "\n",
       "   LotShape_IR2  LotShape_IR3  LotShape_Reg  LandContour_HLS  LandContour_Low  \\\n",
       "0             0             0             1                0                0   \n",
       "1             0             0             1                0                0   \n",
       "2             0             0             0                0                0   \n",
       "\n",
       "   ...  SaleType_ConLI  SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "0  ...               0               0             0             0   \n",
       "1  ...               0               0             0             0   \n",
       "2  ...               0               0             0             0   \n",
       "\n",
       "   SaleType_WD  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0            1                      0                     0   \n",
       "1            1                      0                     0   \n",
       "2            1                      0                     0   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     0                     1                      0  \n",
       "1                     0                     1                      0  \n",
       "2                     0                     1                      0  \n",
       "\n",
       "[3 rows x 162 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rid_cat= pd.get_dummies(data = categ, columns = categ.columns , drop_first = True)\n",
    "rid_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=numer.merge(rid_cat,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating X and y \n",
    "X = merged.drop(['SalePrice'], axis=1)\n",
    "y = merged['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us separate train, test and validation sets\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size = 0.2, random_state = 111)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.2, random_state = 598)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "scaleddata = StandardScaler() # Instantiate\n",
    "scaleddata.fit(X_train_valid) # fit\n",
    "X_train_valid = pd.DataFrame(scaleddata.transform(X_train_valid)) # transform on train_valid set\n",
    "X_test = pd.DataFrame(scaleddata.transform(X_test)) # Transform on test set\n",
    "X_train_valid.columns = X.columns.values\n",
    "X_test.columns = X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shraddha\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.987e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    }
   ],
   "source": [
    "# Setting up lambda values \n",
    "alphas = np.logspace(-10,5,10)\n",
    "\n",
    "score2 = []\n",
    "for a in alphas:\n",
    "    newmodel = Ridge(alpha=a)\n",
    "    newmodel.fit(X_train, y_train) # Fit\n",
    "    score2.append(mean_squared_error(newmodel.predict(X_valid), y_valid)) # Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the validation error and lambda value\n",
    "min(score2)\n",
    "alphas[np.argmin(score2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "scaleddata.fit(X_train_valid) \n",
    "X_train_valid = pd.DataFrame(scaleddata.transform(X_train_valid)) \n",
    "X_test = pd.DataFrame(scaleddata.transform(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0                      1\n",
      "0    -4830.915822             MSSubClass\n",
      "1     6112.598070                LotArea\n",
      "2    11012.352414            OverallQual\n",
      "3     5663.572065            OverallCond\n",
      "4    10141.568018              YearBuilt\n",
      "..            ...                    ...\n",
      "191    645.373013  SaleCondition_AdjLand\n",
      "192    378.029812   SaleCondition_Alloca\n",
      "193   -667.087882   SaleCondition_Family\n",
      "194   2417.043797   SaleCondition_Normal\n",
      "195  -3887.442124  SaleCondition_Partial\n",
      "\n",
      "[196 rows x 2 columns]\n",
      "The prediction error on the testing set is 27246.55704656617\n"
     ]
    }
   ],
   "source": [
    "model3 = Ridge(alpha=alphas[np.argmin(score2)])\n",
    "model3.fit(X_train_valid, y_train_valid)\n",
    "print(pd.DataFrame(zip(model3.coef_,X.columns)))\n",
    "print(\"The prediction error on the testing set is\", np.sqrt(mean_squared_error(model3.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compute the gower distance \n",
    "X = data.drop(['SalePrice'], axis=1) \n",
    "gower = gower.gower_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding k-medoids\n",
    "med = KMedoids(n_clusters=5, random_state = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = med.fit(gower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmedLabel = med.labels_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting variables into equal-sized buckets\n",
    "data['Cluster'] = pd.qcut(data.SalePrice,q=5,labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NMI score is:  0.2149850057771022\n"
     ]
    }
   ],
   "source": [
    "# calculating and printing the NMI (Normalized Mutual Information) score\n",
    "print(\"The NMI score is: \",normalized_mutual_info_score(kmedLabel,data['Cluster'] )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the NMI score is approximately 0.2 which is very close to 0 on a scale of 0 to 1, which means that there is very less correlation between our clusters. To improve these results, let us try different cluster sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NMI score is:  0.2122413966443631\n"
     ]
    }
   ],
   "source": [
    "# let us check with the cluster value of 10\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "med2 = KMedoids(n_clusters=10, random_state = 431)\n",
    "cls2 = med2.fit(gower)\n",
    "kmedLabel2 = med2.labels_\n",
    "data['Cluster'] = pd.qcut(data.SalePrice,q=10,labels=[1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "print(\"The NMI score is: \",normalized_mutual_info_score(kmedLabel2,data['Cluster'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NMI score is:  0.2280597037976478\n"
     ]
    }
   ],
   "source": [
    "# let us check with the cluster value of 20\n",
    "med3 = KMedoids(n_clusters=20, random_state = 345)\n",
    "cls3 = med3.fit(gower)\n",
    "kmedLabel3 = med3.labels_\n",
    "data['Cluster'] = pd.qcut(data.SalePrice,q=20,labels=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "\n",
    "print(\"The NMI score is: \",normalized_mutual_info_score(kmedLabel3,data['Cluster'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that as we keep increasing the value of clusters, the NMI score keeps increasing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
